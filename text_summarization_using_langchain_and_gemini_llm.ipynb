{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyAooPp/wl3VkrY+YF/Wbu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devsjee/Text-Summarization/blob/main/text_summarization_using_langchain_and_gemini_llm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hi there!\n",
        "\n",
        "Text summarization is a beautiful cognitive task in which humans go through a piece of context and somehow magically come up with a gist of it such as in the example below:\n",
        "\n",
        "Text: Psychologist Dr. Jessica Zucker, author of \"I Had a Miscarriage: A Memoir, A Movement,\" tells TODAY.com that people generally refer to a baby born after a pregnancy loss, infant death, stillbirth or miscarriage as a rainbow baby.\n",
        "\n",
        "My Summary: A rainbow baby is a baby born after some kind of loss such as a miscarriage.\n",
        "\n",
        "It is evident that different people will come up with different summaries according to their own perspectives. I have always wondered about how to automatically construct a summary of a given text. There were some very good logical attempts of extractive and absractive summarizations such as using frequency counts, lex rank, text rank, LSA, ESA, Lexical Chains, etc. However, in the current LLM era, deep learning models are achieving close to impeccable results in the text summarization task!"
      ],
      "metadata": {
        "id": "YtWTQ_t7LPeF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why not create a text summarization module using LLMs and experience its summarization skills? I am going to closely follow the below tutorial to build my summarization model.\n",
        "\n",
        "\n",
        "Reference: https://github.com/google/generative-ai-docs/blob/main/examples/gemini/python/langchain/Gemini_LangChain_Summarization_WebLoad.ipynb"
      ],
      "metadata": {
        "id": "oZabFu9gR4ty"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfwfCETSqU3A",
        "outputId": "94cc8b94-93af-44b0-846a-44b0ac013a99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.6/803.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.3/230.3 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --quiet langchain\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet langchain-google-genai"
      ],
      "metadata": {
        "id": "4ht8Vlu2r2l7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ['GOOGLE_API_KEY'] = getpass.getpass(\"Enter the GOOGLE API KEY: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAE_Lf1UsE_N",
        "outputId": "e2a6836c-11cc-4134-ca94-7366744ffa8b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the GOOGLE API KEY: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate\n",
        "from langchain.document_loaders import WebBaseLoader\n"
      ],
      "metadata": {
        "id": "-BnOjqW1xafG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loader = WebBaseLoader(\"https://blog.google/technology/ai/google-gemini-ai/#sundar-note\")\n",
        "#docs = loader.load()\n",
        "#print(docs)"
      ],
      "metadata": {
        "id": "pb6qYVrv0HZ2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm=ChatGoogleGenerativeAI(model=\"gemini-pro\",temperature =0.2, top_p=0.1)"
      ],
      "metadata": {
        "id": "_7oxJhm83Rey"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_prompt = PromptTemplate.from_template(\"{page_content}\")\n",
        "llm_prompt = PromptTemplate.from_template(\"Write a concise summary of the following : {text} \\n\\n Summary:\")\n",
        "\n",
        "print(doc_prompt)\n",
        "print(llm_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oezZTOTi5oe6",
        "outputId": "e827010b-eb23-412b-e6fc-7fdd72668e56"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_variables=['page_content'] template='{page_content}'\n",
            "input_variables=['text'] template='Write a concise summary of the following : {text} \\n\\n Summary:'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema.prompt_template import format_document\n",
        "from langchain.schema import StrOutputParser\n",
        "\n",
        "\"\"\" stuff_chain = (\n",
        "        {\"text\": lambda docs: \"\\n\\n\".join(\n",
        "    format_document(doc, doc_prompt) for doc in docs)}\n",
        "        | llm_prompt | llm | StrOutputParser()\n",
        "        )\n",
        "\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "uKGvg70z-oop",
        "outputId": "aed7e6ca-2843-4e7a-9351-59dfe3325007"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' stuff_chain = (\\n        {\"text\": lambda docs: \"\\n\\n\".join(\\n    format_document(doc, doc_prompt) for doc in docs)}\\n        | llm_prompt | llm | StrOutputParser()\\n        )\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#stuff_chain.invoke(docs)"
      ],
      "metadata": {
        "id": "H9zPMEmyCjHA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the model works, let me check what output it will give for my text in the example shared earlier.\n",
        "\n",
        "Text: Psychologist Dr. Jessica Zucker, author of \"I Had a Miscarriage: A Memoir, A Movement,\" tells TODAY.com that people generally refer to a baby born after a pregnancy loss, infant death, stillbirth or miscarriage as a rainbow baby.\n",
        "\n",
        "My Summary: A rainbow baby is a baby born after some kind of loss such as a miscarriage.\n",
        "\n",
        "Gemini's Summary: ?"
      ],
      "metadata": {
        "id": "SOAsuWMxSUMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.docstore.document import Document\n",
        "\n",
        "docs=[Document(page_content=\"Psychologist Dr. Jessica Zucker, author of 'I Had a Miscarriage: \\\n",
        "A Memoir, A Movement,' tells TODAY.com that people generally refer to a baby born after a pregnancy loss,\\\n",
        " infant death, stillbirth or miscarriage as a rainbow baby.\")]\n",
        "\n",
        "stuff_chain = (\n",
        "        {\"text\": lambda docs: \"\\n\\n\".join(format_document(doc, doc_prompt) for doc in docs)}\n",
        "        | llm_prompt | llm | StrOutputParser()\n",
        "        )\n",
        "\n",
        "stuff_chain.invoke(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "zesF2hABSdnV",
        "outputId": "43a803df-fac0-49b8-8a1c-0f84b679bafb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A rainbow baby is a term used to describe a baby born after a pregnancy loss, infant death, stillbirth, or miscarriage. The term is meant to symbolize hope and joy after a difficult experience.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text: Psychologist Dr. Jessica Zucker, author of \"I Had a Miscarriage: A Memoir, A Movement,\" tells TODAY.com that people generally refer to a baby born after a pregnancy loss, infant death, stillbirth or miscarriage as a rainbow baby.\n",
        "\n",
        "My Summary: A rainbow baby is a baby born after some kind of loss such as a miscarriage.\n",
        "\n",
        "Gemini's Summary: A rainbow baby is a term used to describe a baby born after a pregnancy loss, infant death, stillbirth, or miscarriage. The term is meant to symbolize hope and joy after a difficult experience."
      ],
      "metadata": {
        "id": "WLd8CIgkae7E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "This is interesting, isn't it? has not only selected a key sentence from the given input but also managed to add an additional sentence from its general knowledge bringing out the broad meaning of the term 'rainbow baby'. Gemini also has nicely ignored the details of the psychologist just as I would do :)\n",
        "\n",
        "Also, I tried running the model on the same input multiple times, changed the model parameters (temperature and top_p) but it did not have any effect on the summary generated for the above example."
      ],
      "metadata": {
        "id": "PJYoJ1pmbFeb"
      }
    }
  ]
}